# this shell script is mostly SQL queries to generate flat files
# suitable for creating KBaseSearch.Feature ws objects
# the output files do need to be sorted (mysql sort is often slow)

# ultimately it might be good to convert this to a python script
# but for now it should be sufficient

# prerequisite: set up ./my.cnf with proper creds in current
# working directory

# all SQL queries relatively short (< 5m) unless noted

# define for debugging purposes
limit=' LIMIT 50000 '

# might want to split out Feature and protein sequence
# so that we can leave out protein sequence if it's too big
# ~ 90m for query with protein sequences
echo Feature
time mysql --defaults-extra-file=./my.cnf -e \
 " SELECT f.id,f.id,ioo.from_link,f.sequence_length,f.feature_type,f.source_id,f.function,ps.id,length(ps.sequence),ps.sequence from Feature f left join IsOwnerOf ioo ON (ioo.to_link=f.id) left join IsProteinFor ipf ON (ipf.to_link=f.id) left join ProteinSequence ps ON (ipf.from_link = ps.id) $limit " \
  | perl -pi -e 's/"//g' > Feature.tab

# we're going to add a join to Feature to make sure all outputs
# are valid features
# (some tables have old data)
echo FeatureAlias
time mysql --defaults-extra-file=./my.cnf -e \
 " SELECT fa.id,fa.alias FROM FeatureAlias fa JOIN Feature f ON (fa.id=f.id) $limit " \
  | perl -pi -e 's/"//g' > FeatureAlias.tab

# ~18min
echo HasAliasAssertedFrom
time mysql --defaults-extra-file=./my.cnf -e 'select haaf.from_link as fid,haaf.alias,haaf.to_link as source_db from HasAliasAssertedFrom haaf JOIN Feature f ON (f.id=haaf.from_link)' \
 | perl -pi -e 's/"//g' > HasAliasAssertedFrom.tab

echo AtomicRegulons
time mysql --defaults-extra-file=./my.cnf -e \
 " SELECT ifo.to_link,ifo.from_link FROM IsFormedOf ifo JOIN Feature f ON (ifo.to_link=f.id) $limit " \
  | perl -F\\t -ane 'chomp $F[1];$fid2ar{$F[0]}=$F[1];$count{$F[1]}++;if(eof){print map {$_."\t".$fid2ar{$_}."\t".$count{$fid2ar{$_}}."\n"} sort keys %fid2ar;}' \
  | perl -pi -e 's/"//g' > AtomicRegulons.tab

# for publications, need to use Matt's script, which grabs additional
# metadata from NCBI
echo Publications
time mysql --defaults-extra-file=./my.cnf -e \
 " select ipf.to_link,c.from_link from Concerns c join IsProteinFor ipf on (c.to_link=ipf.from_link) JOIN Feature f ON (ipf.to_link=f.id) $limit " \
  | perl -pi -e 's/"//g' > fids2pubs.tab
# this writes to publications.tab, is probably small enough to
# fit entirely in memory
# if not need to join these two files together
# this actually takes a little while, ~30m?
#cut -f2 fids2pubs.tab | sort -u | python ~/dev_container/modules/search/src/dataExtraction/solrLoad/publications_to_solr.py

echo Family
time mysql --defaults-extra-file=./my.cnf -e \
 " select hm.to_link,fam.id,fam.release,fam.type,ff.family_function from HasMember hm JOIN Family fam ON (hm.from_link=fam.id) join FamilyFunction ff ON (fam.id=ff.id) JOIN Feature f ON (hm.to_link=f.id) $limit " \
  | perl -pi -e 's/"//g' > ProteinFamilies.tab

# ~8m
echo Coexpressed
time mysql --defaults-extra-file=./my.cnf -e \
 " SELECT icw.from_link,icw.to_link,icw.coefficient FROM IsCoregulatedWith icw JOIN Feature f ON (icw.from_link=f.id) $limit " \
  | perl -pi -e 's/"//g' > CoexpressedFids.tab

# ~5m
echo Co_occurring
time mysql --defaults-extra-file=./my.cnf -e \
 " select iip1.from_link,iip2.from_link,ps.score from IsDeterminedBy idb join PairSet ps ON (ps.id=idb.from_link) join IsInPair iip1 ON (iip1.to_link=idb.to_link) join IsInPair iip2 ON (iip2.to_link=idb.to_link and iip2.from_link!=iip1.from_link) JOIN Feature f ON (iip1.from_link=f.id) $limit" \
  | perl -pi -e 's/"//g' > CoOccurringFids.tab

echo Annotation
time mysql --defaults-extra-file=./my.cnf -e \
 " SELECT iab.from_link, a.comment,a.annotator,a.annotation_time FROM Annotation a JOIN IsAnnotatedBy iab ON (iab.to_link=a.id) JOIN Feature f ON (iab.from_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' > Annotation.tab

# ~45m
echo SubsystemData
time mysql --defaults-extra-file=./my.cnf -e \
 " select c.to_link as feature_id,d.from_link as subsystem,v.code as variant,ir.from_link as role from Variant v join IsImplementedBy im ON (v.id=im.from_link) join IsRowOf r on (im.to_link=r.from_link) join Describes d on (v.id=d.to_link) join Includes i on (d.from_link=i.from_link) join Contains c on (c.from_link=r.to_link) join IsRoleOf ir on (ir.to_link = c.from_link and ir.from_link=i.to_link) JOIN Feature f ON (c.to_link=f.id) $limit" \
  | perl -pi -e 's/"//g' > SubsystemData.tab

# ~15m
# this gives dups, need to remove at some point
echo Subsystems
time mysql --defaults-extra-file=./my.cnf -e \
 " select c.to_link,i.from_link from Contains c join IsRoleOf iro ON (c.from_link=iro.to_link) join Includes i ON (iro.from_link=i.to_link) JOIN Feature f ON (c.to_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' > Subsystems.tab

# ~5m
echo Roles
time mysql --defaults-extra-file=./my.cnf -e \
 " select ifi.to_link,ifi.from_link from IsFunctionalIn ifi JOIN Feature f ON (ifi.to_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' > Roles.tab

# not trying to combine these here, but should be able to read both
# in and combine in code
echo RegulonData fids
time mysql --defaults-extra-file=./my.cnf -e \
 " select iri.from_link,iri.to_link from IsRegulatedIn iri JOIN Feature f ON (iri.from_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' > regulonData.members.tab

echo RegulonData tfs
time mysql --defaults-extra-file=./my.cnf -e \
 " select c.from_link,c.to_link from Controls c JOIN Feature f ON (c.from_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' >  regulonData.tfs.tab

# ~6m
echo Locations
time mysql --defaults-extra-file=./my.cnf -e \
 " select ili.from_link,ili.to_link,ili.begin,ili.dir,ili.len,ili.ordinal from IsLocatedIn ili JOIN Feature f ON (ili.from_link=f.id) $limit " \
  | perl -pi -e 's/"//g;s/\\n/ /g' > Locations.tab


echo not getting dna sequences
# query for contig dna seqs:
# select iso.to_link,ico.from_link,hs.to_link,cc.sequence from IsComposedOf ico join IsSequenceOf iso ON (ico.to_link=iso.to_link) join HasSection hs ON (iso.from_link=hs.from_link) join ContigChunk cc ON (hs.to_link=cc.id) limit 5;
# would need to sort by the hs.to_link column, and decode the sequence column 

# don't really need to sort publications file, but can't hurt
# all sorts currently take ~90min
echo sorting files
for file in *.tab
do
  echo sorting $file
  sort -n -k2 -t '.' -T ./tmp -S 48G $file > $file.sorted
done

# extra sort for Subsystems to remove dups; is a bit
# wasteful but not terrible
# (need extra uniq, or sort -u will take only one line per genome)
echo sort -u Subsystems
sort -n -k2 -t '.' -T ./tmp -S 48G Subsystems.tab|uniq > Subsystems.tab.sorted


# now can open .sorted files and stream through them
# use csFlatFiles_to_ws.py script
